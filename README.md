Your setup involves a network topology created in VirtualBox, consisting of five Virtual Machines (VMs): a Controller, a Layer 2 Switch, and three Hosts. The use of VMs introduces some network delay, adding realism to the simulation. You chose to deploy an overlay network, enabling the traffic generated by the hosts to traverse the Switch VM instead of relying on VirtualBox's internal switching mechanism. The hosts and switch utilized Open vSwitch (OVS) with VXLAN tunneling, creating a more complex and realistic network scenario. The Ryu controller was deployed on the Controller VM to manage the network traffic.

Traffic Simulation Using D-ITG
You used the Distributed Internet Traffic Generator (D-ITG) to generate the traffic flows for training your Machine Learning models. D-ITG was chosen for its ability to replicate traffic patterns of various internet applications accurately, providing a realistic dataset for model training. For your classification, you focused on four types of traffic: Ping, Telnet, DNS, and Voice (G.711 codec). These traffic classes were selected based on the capabilities of D-ITG and the specific limitations you encountered.

Data Collection Process
Simulate Traffic: You generated traffic between pairs of hosts using D-ITG or similar tools. Each type of traffic was simulated independently.
Run the Traffic Classifier: You started the traffic classifier script, which also launched the Ryu controller. This script was configured with options relevant to the traffic type being simulated.
Data Collection and Transformation: The script collected data, transforming it to update the attributes of a Flow object. This object captured key characteristics of the traffic flows.
Output to CSV: The Flow object's attributes were periodically saved to a CSV file, providing a structured dataset for each traffic type.
Combine Data: After collecting data for each traffic type, you combined the CSV files into a complete Pandas DataFrame. This combined dataset was then used to train and test your Machine Learning models.

In Jupyter Notebook follows the following steps:
1. Loading and Cleaning Data
2. Supervised Model - Logistic Regression
3. Unsupervised Model - K-Means Clustering
